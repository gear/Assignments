%
% ART.T548 - Advanced artificial intelligence 
% Author: Hoang Nguyen
%
\documentclass[12pt,twoside]{article}

\usepackage{amsmath}

\input{macros}

\setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{0in}
\setlength{\textheight}{8.5in}

% Fill these in!
\newcommand{\theproblemsetnum}{1}
\newcommand{\releasedate}{June 20 - July 4, 2016}
\newcommand{\partaduedate}{Friday, July 15}
\newcommand{\tabUnit}{3ex}
\newcommand{\tabT}{\hspace*{\tabUnit}}

\begin{document}

\handout{Exercise Set \theproblemsetnum}{\releasedate}

\newif\ifsolution
\solutiontrue
\newcommand{\solution}{\textbf{Solution:}}

This exercise set is given in the lecture series by professor Katsumi Inoue.
There are 5 exercises for each lecture:
\begin{enumerate}
  \setlength{\parskip}{0pt}
  \item Lecture No.3 - Exercise 1-1 to 1-3.
  \item Lecture No.4 - Exercise 2-1 to 2-3.
  \item Lecture No.5 - Exercise 3-1 to 3-3.
  \item Lecture No.6 - Exercise 4-1 to 4-3.
  \item Lecture No.7 - Exercise 5-1 to 5-3.
  \item Lecture No.8 - Exercise 6-1 to 6-2.
\end{enumerate}

\setlength{\parindent}{0pt}

\medskip

\hrulefill

\textbf{Collaborators:}
%%% COLLABORATORS START %%%
None.
%%% COLLABORATORS END %%%
\begin{exercises}

\problem

Represent the statement ``It is not true that all P's are not Q's'' in
first-order logic. Then, prove that this is logically equivalent to the
statement ``Some P's are not Q's''.

\ifsolution \solution{}
%%% Ex1 SOLUTION START %%%
By equivalent translation to first-order logic, we have the following
representation: $$\neg (\forall x(P(x) \rightarrow Q(x))$$
$$\equiv \exists x \neg (P(x) \rightarrow Q(x))$$
$$\equiv \exists x \neg ( \neg P(x) \vee Q(x))$$
$$\equiv \exists x (P(x) \wedge \neg Q(x))$$
Therefore, we can claim that ``It is not true that all P's are not Q's'' is logically equivalent to ``Some P's are not Q's''

%%% Ex1 SOLUTION END %%%
\fi

\problem

Prove that the following formulas are valid:
$$\forall x (P(x) \wedge Q(x)) \rightarrow \exists x(P(x) \vee Q(x)) $$
$$\neg \forall x P(x) \leftrightarrow \exists x \neg P(x) $$
\ifsolution \solution{}
%%% Ex2 SOLUTION START %%%
First, we have: $\forall x (P(x) \wedge Q(x)) \rightarrow \exists x(P(x) \vee Q(x)) $
$$\equiv \neg \forall x (P(x) \wedge Q(x))\vee \exists x (P(x) \vee Q(x)) $$
$$\equiv \exists x \neg (P(x) \wedge Q(x))\vee \exists x (P(x) \vee Q(x)) $$
$$ \equiv \exists x(\neg P(x) \vee \neg Q(x)) \vee \exists x (P(x) \vee Q(x)) $$
If the left part of the last formula isn't true, then both P(x) and Q(x) are true $\forall$ x and the right part is absolutely true. If the right section is not true, then P(x) and Q(x) are not true $\forall$ x and the left section is absolutely true. Therefore, we claim this formula is valid.

Second, viewing the case for $\rightarrow$ assuming that the case $\leftarrow$ is valid, we have:
$$\neg \forall x P(x) \rightarrow \exists x \neg P(x)$$
$$\equiv \neg \neg \forall x P(x) \vee \neg \exists x \neg P(x)$$
$$\equiv \forall x P(x) \vee \neg \forall x P(x) $$
Viewing the case for $\leftarrow$ assuming that the case $\rightarrow$ is valid, we have:
$$\exists x P(x) \rightarrow \neg \forall x P(x) $$
$$\equiv \neg \exists x \neg P(x) \vee \neg \forall x P(x)$$
$$\equiv \neg \exists x \neg P(x) \vee \exists x \neg P(x)$$
Therefore, the formula is valid.
%%% Ex2 SOLUTION END %%%
\fi

\problem

Prove that the following formula is not valid:
$$ \exists x (P(x) \wedge Q(x)) \leftrightarrow \exists  x P(x) \wedge \exists x Q(x) $$
\ifsolution \solution{}
%%% Ex3 SOLUTION START %%%
We only need to prove the necessity condition is wrong. Assume there are two constant A and B. When P(x) is satisfied by only A, and Q(x) is satisfied by only B, there exists no x which can satisfy both P(x) and Q(x). Therefore, the formula is not valid.

%%% Ex3 SOLUTION END %%%
\fi

\textbf{Exercise 2-1.}

Suppose the formula $T = \{P \rightarrow R , Q \rightarrow R\}$ and $\varphi = P \rightarrow R$.Using Hilbert System, prove that $\varphi$ is a theorem of T.

\ifsolution \solution{}
From the assumption, we derive the following formula:
$$((P \rightarrow Q) \rightarrow (Q \rightarrow R)) \rightarrow ((P \rightarrow Q ) \rightarrow (P \rightarrow R))$$
By MP, we have:
$$\frac{P \rightarrow Q \qquad (P \rightarrow Q) \rightarrow (P \rightarrow R) }{P \rightarrow R} $$
Therefore, $\varphi$ is a theorem of T.
\fi

\textbf{Excercise 2-2.}

Using DPLL, show that the next clausal theory is unsatisfiable:
$$S = \{\neg P \vee Q \vee R, \neg Q \vee R, Q \vee \neg R, \neg Q \vee \neg R, P \}$$

\ifsolution \solution{}
Assume S is the formula as input of DPLL:
$$(\neg P \vee Q \vee R) \wedge (\neg Q \vee R) \wedge (Q \vee \neg R) \wedge (\neg Q \vee \neg R) \wedge (P)) $$
There is a unit P, so we can simplify the formula by unit propagation:
$$(Q \vee R) \wedge (\neg Q \vee R) \wedge (Q \vee \neg R) \wedge(\neg Q \vee \neg R) $$
DPLL selects the variable Q and selects $(S \wedge Q)$:
$$(Q \vee R) \wedge (\neg Q \vee R) \wedge (Q \vee \neg R) \wedge(\neg Q \vee \neg R) \wedge (Q) $$
DPLL assigns Q = T and calls $(R \wedge \neg R)$. Since this is unsatisfiable, DPLL calls $(S \wedge \neg Q)$:
$$(Q \vee R) \wedge (\neg Q \vee R) \wedge (Q \vee \neg R) \wedge(\neg Q \vee \neg R) \wedge (\neg Q) $$
DPLL assigns Q = F and calls $(R \wedge \neg R)$. So DPLL returns unsatisfiable. Therefore, S is unsatisfiable
\fi

\textbf{Exercise 2-3.}

State the reason why WalkSAT is not complete.

WalkSAT is not complete because, firstly, it conducts stochastic local search, secondly, while WalkSAT can show the satisfiability it can not show the unsatisfiability, and finally, WalkSAT will return unknown when cannot reach the solution in a specific time.

\textbf{Exercise 2-3.}

What is a problem of the direct encoding of CSP to SAT? Is
there any other encoding method to solve the problem?

The problem of direct encoding is that is doesn't count the relationship of the order of variables and constants. As a result, the size of SAT which is transfered form CSP will be very large.

Order encoding will improve the problem. It represents the order of variables and constants. Therefore the size of SAT transfered will be smaller than using encoding.

\textbf{Exercise 3-1.}

Translate the following prenex normal form to the
Skolem normal form:
$$\forall y \forall z \exists u (\neg p(x,z) \vee q(x,y,u))\wedge (\neg p(y,z) \vee q(q,y,u))$$
\ifsolution \solution{}
We have: $\forall y \forall z \exists u (\neg p(x,z) \vee q(x,y,u))\wedge (\neg p(y,z) \vee q(q,y,u))$

$\equiv \forall y \forall z (\neg p(x,z) \vee q(x,y,f(y.z))\wedge (\neg p(y,z) \vee q(q,y,f(y,z)))$ where $f(y,z)$ is  skolem function.
\fi

\textbf{Exercise 3-2.}

Prove that groundparent(hanako,ichiro) is a logical
consequence of the definite program: 
$$P= \{groundparent(x,y) \leftarrow parent(x,z),parent(x,z). Parent(x,y) \leftarrow father(x,y). parent(x,y) \leftarrow mother(x,y). father(makoto,ichiro). mother(hanako,makoto). \}$$
\ifsolution \solution{}
Using SLD resolution to P and while considering $\leftarrow$ grandparent(hanako,ichiro) as the goal, we lead to an empty clause as in Fig 1.Therefore, groundparent(hanako,ichiro) is the consequence of P.
\fi

\textbf{Exercise 3-3.}

Selling unregistered guns is a crime. “Red” has some
unregistered guns and he bought those from “Lefty”. Derive
that “Lefty” is criminal.

\ifsolution \solution{}
We define a logic program as follow:
\begin{center}
criminal(x) means x is criminal sell(x,y) 

means x sold y
\end{center}
And the definite program is follow:
\begin{center}
P = {criminal(x)$\leftarrow $
sell(x,unregistered guns) sell(Lefty,unregistered guns)}
\end{center}

By SLD resolution, we derive an empty clause as in Fig 2, so Lefty is criminal. 
\fi

\textbf{Exercises 4-1.}

Why our world is not symmetric, that is, there are much more negative facts than positive ones? How can our human cope with this situation?

Our world is not symmetric because, when people suffer from negative fact, they had negative mind and they might induce negative fact, while people in their position condition, they won't cause positive fact.

We can deal with this situation by patience and benevolence. Which means that we have to refrain ourselves from doing negative fact when we in negative mind. And we have to cause positive fact when we are positive. By doing this, negative facts will be minimized and positive ones is greatly increased.

\textbf{Exercise 4-2.}
Compute the stable models of the problem:
$$P = \{p \leftarrow \textbf{not} \ p, \ p \leftarrow q. \ q \leftarrow \textbf{not} \ r. \ r \leftarrow \textbf{not} \ q \}$$
\ifsolution \solution{}
The stable model of $P = {p \leftarrow not \ p. \ p \leftarrow \ q. \ q \leftarrow not \ r. \ r \leftarrow not \ q.}$ is the set$\{p,q\}$. 
\fi

\textbf{Exercise 4-3.}
(Lottery paradox) Suppose 1000 fair lottery ticket in which only the one ticket is winning. It is rational to predict that ticket $\#$ 1 will not win. Since the lottery is fair, it is also rational to assume that ticket $\#$2 will not win either. Indeed, it is rational to accept for any number k (k = 1,...,1000) that ticket $\#$ k will not win. However, accepting all these statements entails that it is rational to accept that no ticker will win, which contradicts with the fact that one will win. Describe this problem in formalism of nonmonotonic reasoning and show that the problem does not appear in it.

\ifsolution \solution{}
We describe the sentences by using default logic. First, the default is ''the lottery tickets are normally not win''. We describe the sentence as the following:
$$\frac{lottery(x): \neg win(x)}{\neg win(x)}$$
where lottery(x) means x is a ticket, win(x) means x is the winning ticket. Since we have the assumption that all 1000 tickets are fair and there will always is a winning one, describing the statements in first order logic, we have:
$$\exists x(lottery(x) \rightarrow win(x))$$
Assume ticket $t_k$ is winning one, then the following formula is true:
$$lottery(t_k) \rightarrow win(t_k)$$
Substiting $x$ by $t_k$ in the default, we derive $\neg win(t_k)$ is not true. Therefore, there is no paradox.
\fi

\textbf{Exercise 5-1.}

Write a successor state axiom for Block world, which replaces 
the axioms (2), (3) and (4).

\ifsolution \solution{}

$(2) \ poss(a,s)$ $\rightarrow$
$$[On(x,z,do(a,s))\wedge \ Clear(y,do(a,s)) \leftrightarrow (a = Move(x,z)) \vee ((On(x,z,s) \wedge Clear(y,s)) \vee a , Move(x,y))]$$

$(3) \ poss(a,s) \wedge a , \ Move(x,z) \rightarrow \  (On(x,y,do(a,s)) \leftrightarrow  On(x,y,s))$

$(4) \ poss(a,s) \wedge a , \ Move(y,x) \rightarrow (Clear(x,do(a,s)) \leftrightarrow Clear(x,s))$ 
\fi

\textbf{Exercise 5-2.}

Consider a solution to the ramification problem.

\ifsolution \solution{}
The notion of a solitary stratiﬁed theory is defined by combining the notion of solitary theory and stratiﬁed logic program. A solitary stratiﬁed theory is a stratiﬁed logic program that allows negation in the consequent. There is a closed-form solution to the frame and ramiﬁcation problems for axiomatizations whose syntactic representation of ramiﬁcation constraints and eﬀect axioms, collectively form a solitary stratiﬁed theory. 7 steps syntactic manipulation procedure which results in a closed-form solution to the frame and ramiﬁcation problems are deﬁned. Let T be a solitary stratiﬁed theory, with stratiﬁcation $(T_1,T_2,··· ,T_n) $. 

\textbf{Step1}. For every fluent $F_i$ defined in an eﬀect axioms of $T_i$ generate at most one general positive and one general negative eﬀect axiom. 

\textbf{Step2}. For every fluent $F_i$ defined in a ramification constraint of $T_i$,generate general positive and negative ramification axioms, relativized to situation (do(a,s)). 

\textbf{Step3}. Combine the two sets of axioms above,to define extended positive and negative effect axioms, for every fluent $F_i$

\textbf{Step4}. Make the following completeness assumption regarding the effects and ramifications. All the conditions under which an action a can lead, directly or indirectly, to ﬂuent F becoming true or false in the successor state are characterized in the extended positive and negative effect axioms for ﬂuent F.

\textbf{Step5}. From the completeness assumption, generate explanation closure axioms.

\textbf{Step6}.
From the extended positive and negative effect axioms and the explanation closure axioms, define intermediate successor state axioms for each fluent $F_i$.

\textbf{Step7}. By regressing the intermediate successor state axioms, generate (ﬁnal) successor state axioms. This ﬁnal successor state axioms provide a closed-form solution to the ramiﬁcation problems.
\fi

\textbf{Exercise 5-3.}

Can intelligence emerge from machines/computers? State your opinion with reasons for it.

\ifsolution \solution{}

I think human-level intelligence can and will emerge within this century. My belief based on the demand of artificial intelligence and the natural science discovery. With the maturity of digital technology and emergence of quantum computing, we are now in need of smarter machine more than ever. We produce 2.5 Quintillion Bytes per day, which is out of human ability to analyze. Without smart machines, we will soon be drown with our own data. Furthermore, artificial intelligence has been making our lives more comfortable everyday. Thus, human-level intelligence is one of mankind's top priority. 

In a nutshell, a human body is a biological machine which operates by the laws of physics. The human's brain, albeit complicated, still follows the laws physics. Like all the natural sciences, the study of artificial intelligence can be broken down to observation and modeling. Every years, we create sophisticated tools to monitor how our brain works. The results from biology and cognitive science are viewed as ``ground-truth'' for models in computer science. This process then repeats over and over until we find the best model for our brain's operation. In the recent 100 years, we have discovered more technology and we did all the time before. I believe with the current speed of technology discovery and the high demand for artificial intelligence, our dream machine is within the foreseeable future.
\fi

\textbf{Exercise 6-1.}

Show two simple examples of applications of abduction in such areas as design, diagnosis, discovery, dperception, intension recognition, and natural language understanding.

\ifsolution \solution{}

\textbf{Example 1:} Consider the following simplistic knowledge base and assumables for a diagnostic assistant:

\begin{itemize}
  \setlength{\parskip}{0pt}
  \item bronchitis \leftarrow influenza.
  \item bronchitis \leftarrow smokes.
  \item coughing \leftarrow bronchitis.
  \item wheezing \leftarrow bronchitis.
  \item fever \leftarrow influenza.
  \item soreThroat \leftarrow influenza.
  \item false \leftarrow smokes $\wedge$ nonsmoker.
  \item \textbf{assumable} smokes, nonsmoker, influenza.
\end{itemize}

If the agent observes wheezing, there are two minimal explainations: \\
\vspace{5em} \{influenza\} and \{smokes\} \\
The explainations imply bronchitis and coughing.

\textbf{Example 2:} Refrigerator Design:

While refrigerators are originally simple


\fi


\end{exercises}


\end{document}
